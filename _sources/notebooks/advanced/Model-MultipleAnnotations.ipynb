{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d55ab60",
   "metadata": {},
   "source": [
    "# Model - Multiple Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a813d7",
   "metadata": {},
   "source": [
    "> ### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb77ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from iqual import iqualnlp, evaluation, crossval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a42bc8",
   "metadata": {},
   "source": [
    "> ### Load `annotated (human-coded)` and `unannotated` datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7d035ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir         = \"../../data\"\n",
    "human_coded_df   = pd.read_csv(os.path.join(data_dir,\"annotated.csv\"))\n",
    "uncoded_df       = pd.read_csv(os.path.join(data_dir,\"unannotated.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b308f43",
   "metadata": {},
   "source": [
    "> ### Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f95233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: 7470\n",
      "Test Size: 2490\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(human_coded_df,test_size=0.25)\n",
    "print(f\"Train Size: {len(train_df)}\\nTest Size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea3ad2",
   "metadata": {},
   "source": [
    "> ### Configure training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebffbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select Question and Answer Columns\n",
    "question_col = 'Q_en'\n",
    "answer_col   = 'A_en'\n",
    "\n",
    "### Select a code\n",
    "code_variables = ['religious','migration','entrepreneur','secular','marriage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e369c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scorig Dict for evaluation\n",
    "scoring_dict = evaluation.get_scoring_dict(['f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ce910",
   "metadata": {},
   "source": [
    "> ### Configure a Hyperparameter Grid for cross-validation + fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1317cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paths for precomputed vectors created using `sentence-transformers`\n",
    "dict_dir          = \"../dictionaries\"\n",
    "sbert_models      = [\"all-mpnet-base-v2\", \"distiluse-base-multilingual-cased-v2\"]\n",
    "sbert_model_paths = [os.path.join(dict_dir,m+'.pkl') for m in sbert_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d11e1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "SBERT_QA_PARAMS = {\n",
    "    \"Input\":{\n",
    "        \"question\":{\n",
    "            \"vectorizer\":{\n",
    "                        \"model\":sbert_model_paths,\n",
    "                        \"env\":[\"saved-dictionary\"],               \n",
    "                         },\n",
    "        },\n",
    "        \"answer\":{\n",
    "            \"vectorizer\":{\n",
    "                        \"model\":sbert_model_paths,\n",
    "                        \"env\":[\"saved-dictionary\"],                \n",
    "                         },                        \n",
    "        },\n",
    "    }\n",
    "}\n",
    "SBERT_A_PARAMS = {\n",
    "    \"Input\":{\n",
    "        \"question\":\"drop\",\n",
    "        \"answer\":{\n",
    "            \"vectorizer\":{\n",
    "                        \"model\":sbert_model_paths,\n",
    "                        \"env\":[\"saved-dictionary\"],\n",
    "                        },\n",
    "        }\n",
    "}\n",
    "}\n",
    "\n",
    "SKLEARN_QA_PARAMS =     {\n",
    "    \"Input\":{\n",
    "        \"question\":{\n",
    "            \"vectorizer\":{\n",
    "                        \"model\":['TfidfVectorizer','CountVectorizer'],\n",
    "                        \"max_features\":[500,1000,1500,2500,],\n",
    "                        \"env\":[\"scikit-learn\"],               \n",
    "                         },\n",
    "        },\n",
    "        \"answer\":{\n",
    "            \"vectorizer\":{\n",
    "                        \"model\":['TfidfVectorizer','CountVectorizer'],\n",
    "                        \"max_features\":[1500,2500,4000,],\n",
    "                        \"env\":[\"scikit-learn\"],                \n",
    "                         },                        \n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "SKLEARN_A_PARAMS = {\n",
    "    \"Input\":{\n",
    "        \"question\":\"drop\",\n",
    "        \"answer\":{\n",
    "            \"vectorizer\":{\n",
    "                        \"model\":['TfidfVectorizer','CountVectorizer'],\n",
    "                        \"max_features\":[1500,2500,4000,],\n",
    "                        \"env\":[\"scikit-learn\"],\n",
    "                            },\n",
    "        }   \n",
    "    }\n",
    "}\n",
    "\n",
    "LOGISTIC_PARAMS = {       \n",
    "    \"Classifier\":{\n",
    "            \"model\":[\"LogisticRegression\"],\n",
    "            \"C\":[0.01,0.1],\n",
    "        },\n",
    "}\n",
    "\n",
    "RANDOM_FOREST_PARAMS = {\n",
    "    \"Classifier\":{\n",
    "            \"model\":[\"RandomForestClassifier\"],\n",
    "            \"n_estimators\":[100,200],\n",
    "            \"max_depth\":[5,10,15],\n",
    "        },\n",
    "}\n",
    "\n",
    "SGD_PARAMS = {\n",
    "    \"Classifier\":{\n",
    "            \"model\":[\"SGDClassifier\"],\n",
    "            \"loss\":[\"hinge\",\"log\"],\n",
    "            \"alpha\":[0.0001,0.001],\n",
    "        },\n",
    "}\n",
    "\n",
    "### Combine a Vectorizer and Classifier\n",
    "VECTORIZATION_PARAMS = [SKLEARN_QA_PARAMS,SKLEARN_A_PARAMS,SBERT_QA_PARAMS,SBERT_A_PARAMS]\n",
    "CLASSIFIER_PARAMS    = [LOGISTIC_PARAMS,RANDOM_FOREST_PARAMS,SGD_PARAMS]\n",
    "\n",
    "params_all = [{**vect_params, **clf_params} for vect_params in VECTORIZATION_PARAMS for clf_params in CLASSIFIER_PARAMS]\n",
    "CV_SEARCH_PARAMS = [crossval.convert_nested_params(params) for params in params_all]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5250bd6d",
   "metadata": {},
   "source": [
    "> ## Model training:\n",
    "> Cross-validate over hyperparameters and select the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa163fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "religious\n",
      ".......720 hyperparameters configurations possible.....\n",
      "Average F1 score for religious: 0.628\n",
      "migration\n",
      ".......720 hyperparameters configurations possible.....\n",
      "Average F1 score for migration: 0.653\n",
      "entrepreneur\n",
      ".......720 hyperparameters configurations possible.....\n",
      "Average F1 score for entrepreneur: 0.680\n",
      "secular\n",
      ".......720 hyperparameters configurations possible.....\n",
      "Average F1 score for secular: 0.498\n",
      "marriage\n",
      ".......720 hyperparameters configurations possible.....\n",
      "Average F1 score for marriage: 0.810\n"
     ]
    }
   ],
   "source": [
    "fitted_models = {}\n",
    "for code_var in code_variables:\n",
    "    print(code_var)\n",
    "    \n",
    "    ### Create X and y\n",
    "    X = train_df[[question_col,answer_col]]\n",
    "    y = train_df[code_var]\n",
    "    \n",
    "    iqual_model = iqualnlp.Model()\n",
    "    iqual_model.add_text_features(question_col,answer_col,model='TfidfVectorizer',env='scikit-learn')\n",
    "    iqual_model.add_classifier(name=\"LogisticRegression\")\n",
    "    iqual_model.add_threshold()\n",
    "    iqual_model.compile()\n",
    "    cv_dict = iqual_model.cross_validate_fit(\n",
    "        X,y,                                # X: Pandas DataFrame of features, y: Pandas Series of labels\n",
    "        search_parameters=CV_SEARCH_PARAMS, # search_parameters: Dictionary of parameters to use for cross-validation\n",
    "        cv_method='RandomizedSearchCV',     # cv_method: Cross-validation method to use, options: GridSearchCV, RandomizedSearchCV\n",
    "        n_iter=10,                          # n_iter: Only when cv_method='RandomizedSearchCV'\n",
    "        scoring=scoring_dict,               # scoring: Scoring metric to use for cross-validation    \n",
    "        refit='f1',                         # refit: Metric to use for refitting the model\n",
    "        n_jobs=-1,                          # n_jobs: Number of parallel threads to use  \n",
    "        cv_splits=3,                        # cv_splits: Number of cross-validation splits\n",
    "    )\n",
    "    print()\n",
    "    print()\n",
    "    print(\"Average F1 score for {code_var}: {score:.3f}\".format(code_var=code_var,score=cv_dict['avg_test_score']))\n",
    "    \n",
    "    # Save fitted model to a dictionary\n",
    "    fitted_models[code_var] = iqual_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7575dd4",
   "metadata": {},
   "source": [
    "### Evaluate model using out sample data (Held out human-coded data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e771963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-sample F1-score for religious is : 0.651\n",
      "Out-sample F1-score for migration is : 0.667\n",
      "Out-sample F1-score for entrepreneur is : 0.619\n",
      "Out-sample F1-score for secular is : 0.440\n",
      "Out-sample F1-score for marriage is : 0.830\n"
     ]
    }
   ],
   "source": [
    "for code_var in code_variables:\n",
    "    test_pred = fitted_models[code_var].predict(test_df[['Q_en','A_en']])\n",
    "    test_act  = test_df[code_var].tolist()\n",
    "    f1_score  = evaluation.calc_f1_score_from_labels(test_pred,test_act)\n",
    "    print(f\"Out-sample F1-score for {code_var} is : {f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f3255a",
   "metadata": {},
   "source": [
    "### Predict labels for unannotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "626b81f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tExamples of positive religious predictions:\n",
      "\n",
      "\t===============================================\n",
      "\n",
      "\n",
      "Q: Bro, what kind of work do you think Nur Arafat will do when he grows up?\n",
      "A: Maulana will grow up to serve religion.\n",
      "\n",
      "Q: If God blesses you, who will be your sons when they grow up?\n",
      "A: My son Yahya will be the Mufti of the Fatwa Department, a researcher of the Big Book (Hadith Sharif). Hafez will be in the Koran.\n",
      "\n",
      "Q: So what did you say, brother?\n",
      "A: The knowledge of the world is called the world. There is a knowledge of the hereafter. If my son can teach people about the hereafter in madrasas, mosques. I like that.\n",
      "\n",
      "\tExamples of positive migration predictions:\n",
      "\n",
      "\t===============================================\n",
      "\n",
      "\n",
      "Q: What other dreams do you have for him after making him master, tell me a little?\n",
      "A: Apart from that, his necessary travel documents, clothes, etc. are all these.\n",
      "\n",
      "Q: Yes, how to do that?\n",
      "A: I will send visa abroad with a relative.\n",
      "\n",
      "Q: What to send abroad for?\n",
      "A: For the good of the nation.\n",
      "\n",
      "\tExamples of positive entrepreneur predictions:\n",
      "\n",
      "\t===============================================\n",
      "\n",
      "\n",
      "Q: What do you dream about your child, what hope do you have? tell me\n",
      "A: I wanted to educate my younger son, I wanted to open a shop for my elder son, I couldn't, I wanted to build a house, the house broke down in monsoon, I couldn't either. I am in more trouble now.\n",
      "\n",
      "Q: yes,\n",
      "A: Sis, I already told you. If you give me a chance, maybe I can run a cloth shop or a rice shop. Sister, these are talking about capital.\n",
      "\n",
      "Q: So what do you want? Oki will work or do business.\n",
      "A: Which he likes. Whatever the job or business. We can live in peace. That's what I want\n",
      "\n",
      "\tExamples of positive secular predictions:\n",
      "\n",
      "\t===============================================\n",
      "\n",
      "\n",
      "Q: Brother, what are your future plans with your children?\n",
      "A: The future plan is to live with people in the society and the area with respect. And can join any job by studying for it. Then they can shape their own beautiful future.\n",
      "\n",
      "Q: Well. Do you pray to God for your son?\n",
      "A: Yes. I give thousands of thanks to Allah. To give us a beautiful life.\n",
      "\n",
      "Q: Uncle, what hope do you have for your elder daughter Roksana Begum?\n",
      "A: I hope to educate him. I will marry him after studying. He will live happily ever after.\n",
      "\n",
      "\tExamples of positive marriage predictions:\n",
      "\n",
      "\t===============================================\n",
      "\n",
      "\n",
      "Q: What to do for the rest of your life?\n",
      "A: I will get married when I grow up.\n",
      "\n",
      "Q: What are the plans or thoughts of the future of the brothers?\n",
      "A: Let the boys study. I will get a job after finishing my studies. If not, if any shop or business can do it, I will do it. If there are girls, I will marry them if they have money. This is my dream.\n",
      "\n",
      "Q: How have you thought about fulfilling all your dreams? How can you marry a good girl or get a job? What have you planned?\n",
      "A: As for what I am doing, I am saving some money from running the family. If my daughter gets a good job, if she doesn't get a job, I will see a good family and get her married.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for code_var in code_variables:\n",
    "    uncoded_df[code_var+'_pred'] = fitted_models[code_var].predict(uncoded_df[['Q_en','A_en']])\n",
    "    print(f\"\\tExamples of positive {code_var} predictions:\\n\")\n",
    "    print('\\t===============================================\\n\\n')\n",
    "    for idx, row in uncoded_df.loc[(uncoded_df[code_var+\"_pred\"]==1),['Q_en','A_en']].sample(3).iterrows():\n",
    "        print(\"Q: \",row['Q_en'],\"\\n\",\"A: \", row['A_en'],sep='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d6e0189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest parameters for religious:\n",
      "\n",
      " {'Input__question__vectorizer__model': 'TfidfVectorizer', 'Input__question__vectorizer__max_features': 500, 'Input__question__vectorizer__env': 'scikit-learn', 'Input__answer__vectorizer__model': 'TfidfVectorizer', 'Input__answer__vectorizer__max_features': 4000, 'Input__answer__vectorizer__env': 'scikit-learn', 'Classifier__n_estimators': 100, 'Classifier__model': 'RandomForestClassifier', 'Classifier__max_depth': 10}\n",
      "\n",
      "\tBest parameters for migration:\n",
      "\n",
      " {'Input__answer__vectorizer__model': '../dictionaries\\\\distiluse-base-multilingual-cased-v2.pkl', 'Input__answer__vectorizer__env': 'saved-dictionary', 'Classifier__model': 'SGDClassifier', 'Classifier__loss': 'hinge', 'Classifier__alpha': 0.0001}\n",
      "\n",
      "\tBest parameters for entrepreneur:\n",
      "\n",
      " {'Input__question__vectorizer__model': 'CountVectorizer', 'Input__question__vectorizer__max_features': 2500, 'Input__question__vectorizer__env': 'scikit-learn', 'Input__answer__vectorizer__model': 'CountVectorizer', 'Input__answer__vectorizer__max_features': 1500, 'Input__answer__vectorizer__env': 'scikit-learn', 'Classifier__n_estimators': 200, 'Classifier__model': 'RandomForestClassifier', 'Classifier__max_depth': 15}\n",
      "\n",
      "\tBest parameters for secular:\n",
      "\n",
      " {'Input__answer__vectorizer__model': 'TfidfVectorizer', 'Input__answer__vectorizer__max_features': 2500, 'Input__answer__vectorizer__env': 'scikit-learn', 'Classifier__n_estimators': 200, 'Classifier__model': 'RandomForestClassifier', 'Classifier__max_depth': 10}\n",
      "\n",
      "\tBest parameters for marriage:\n",
      "\n",
      " {'Input__question__vectorizer__model': 'CountVectorizer', 'Input__question__vectorizer__max_features': 1000, 'Input__question__vectorizer__env': 'scikit-learn', 'Input__answer__vectorizer__model': 'TfidfVectorizer', 'Input__answer__vectorizer__max_features': 1500, 'Input__answer__vectorizer__env': 'scikit-learn', 'Classifier__n_estimators': 100, 'Classifier__model': 'RandomForestClassifier', 'Classifier__max_depth': 10}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for code_var in code_variables:\n",
    "    best_params = fitted_models[code_var].cv.get_best_params()\n",
    "    print(f\"\\tBest parameters for {code_var}:\\n\\n\",best_params,end='\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969c34c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
